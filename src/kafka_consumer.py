from kafka import KafkaConsumer
import json
import joblib
import numpy as np
from datetime import datetime
from elasticsearch import Elasticsearch
import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("üéØ KAFKA CONSUMER - PR√âDICTIONS ML EN TEMPS R√âEL")
print("=" * 60)

# Configuration
KAFKA_BROKER = 'localhost:9092'
TOPIC_NAME = 'user-events'
ELASTICSEARCH_HOST = 'http://localhost:9200'

# Charger le mod√®le ML
print("\nü§ñ Chargement du mod√®le ML...")
try:
    model = joblib.load('models/purchase_predictor.pkl')
    with open('models/feature_names.json', 'r') as f:
        feature_names = json.load(f)
    print("‚úÖ Mod√®le charg√© avec succ√®s")
except Exception as e:
    print(f"‚ùå Erreur de chargement du mod√®le : {e}")
    exit(1)

# Connexion √† Elasticsearch (optionnel)
try:
    es = Elasticsearch([ELASTICSEARCH_HOST])
    if es.ping():
        print("‚úÖ Connect√© √† Elasticsearch")
        
        # Cr√©er l'index s'il n'existe pas
        index_name = 'ecommerce-predictions'
        if not es.indices.exists(index=index_name):
            es.indices.create(index=index_name)
            print(f"‚úÖ Index '{index_name}' cr√©√©")
    else:
        print("‚ö†Ô∏è Elasticsearch non disponible. Les pr√©dictions ne seront pas sauvegard√©es.")
        es = None
except Exception as e:
    print(f"‚ö†Ô∏è Impossible de se connecter √† Elasticsearch : {e}")
    es = None

# Cr√©er le consumer Kafka
print(f"\nüì° Connexion au broker Kafka : {KAFKA_BROKER}")
try:
    consumer = KafkaConsumer(
        TOPIC_NAME,
        bootstrap_servers=KAFKA_BROKER,
        value_deserializer=lambda m: json.loads(m.decode('utf-8')),
        auto_offset_reset='latest',  # Lire uniquement les nouveaux messages
        enable_auto_commit=True,
        group_id='ml-prediction-group'
    )
    print(f"‚úÖ Abonn√© au topic : {TOPIC_NAME}")
except Exception as e:
    print(f"‚ùå Erreur de connexion √† Kafka : {e}")
    exit(1)

def prepare_features(event):
    """Pr√©parer les features pour le mod√®le"""
    
    # Cr√©er le dictionnaire de features
    features_dict = {
        'clicks': event['clicks'],
        'cart_adds': event['cart_adds'],
        'avg_price': event['avg_price'],
        'time_on_page': event['time_on_page'],
        'hour_of_day': event['hour_of_day'],
        'day_of_week': event['day_of_week'],
        'is_weekend': event['is_weekend'],
        'products_viewed': event['products_viewed'],
        'has_purchased_before': event['has_purchased_before']
    }
    
    # One-hot encoding pour la cat√©gorie
    categories = ['Electronics', 'Clothing', 'Home', 'Books', 'Sports', 'Beauty']
    for cat in categories:
        features_dict[f'cat_{cat}'] = 1 if event['category'] == cat else 0
    
    # Cr√©er le vecteur dans le bon ordre
    feature_vector = [features_dict[name] for name in feature_names]
    
    return np.array([feature_vector])

def save_to_elasticsearch(event, prediction, probability):
    """Sauvegarder la pr√©diction dans Elasticsearch"""
    
    if es is None:
        return
    
    try:
        document = {
            'timestamp': event['timestamp'],
            'user_id': event['user_id'],
            'product_id': event['product_id'],
            'category': event['category'],
            'price': event['avg_price'],
            'clicks': event['clicks'],
            'cart_adds': event['cart_adds'],
            'prediction': 'purchase' if prediction == 1 else 'no_purchase',
            'probability': float(probability),
            'processed_at': datetime.now().isoformat()
        }
        
        es.index(index='ecommerce-predictions', document=document)
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur Elasticsearch : {e}")

# Compteurs et statistiques
total_processed = 0
predicted_purchases = 0
predicted_no_purchases = 0
high_prob_purchases = 0  # probabilit√© > 70%

print("\n" + "=" * 60)
print("üëÇ EN √âCOUTE DES √âV√âNEMENTS...")
print("   Appuyez sur Ctrl+C pour arr√™ter")
print("=" * 60 + "\n")

try:
    for message in consumer:
        event = message.value
        
        try:
            # Pr√©parer les features
            features = prepare_features(event)
            
            # Faire la pr√©diction
            prediction = model.predict(features)[0]
            probability = model.predict_proba(features)[0][1]
            
            # Incr√©menter les compteurs
            total_processed += 1
            
            if prediction == 1:
                predicted_purchases += 1
                if probability >= 0.7:
                    high_prob_purchases += 1
            else:
                predicted_no_purchases += 1
            
            # Afficher le r√©sultat
            timestamp = datetime.now().strftime('%H:%M:%S')
            
            if prediction == 1:
                emoji = "üõí" if probability >= 0.7 else "üîî"
                status = "ACHAT PROBABLE" if probability >= 0.7 else "Achat possible"
                color = "\033[92m"  # Vert
            else:
                emoji = "‚ùå"
                status = "Pas d'achat"
                color = "\033[91m"  # Rouge
            
            reset = "\033[0m"  # Reset couleur
            
            print(f"{color}[{timestamp}] {emoji} {status}{reset}")
            print(f"   üë§ User: {event['user_id']} | üì¶ Product: {event['product_id']}")
            print(f"   üè∑Ô∏è Cat√©gorie: {event['category']} | üí∞ Prix: {event['avg_price']}‚Ç¨")
            print(f"   üñ±Ô∏è Clics: {event['clicks']} | üõí Panier: {event['cart_adds']}")
            print(f"   üìä Probabilit√© d'achat: {probability:.2%}")
            
            # Recommandation
            if probability >= 0.7:
                print(f"   üí° Action: MONTRER UNE PROMO MAINTENANT !")
            elif probability >= 0.4:
                print(f"   üí° Action: Envoyer email de rappel")
            elif probability >= 0.2:
                print(f"   üí° Action: Proposer produits similaires")
            else:
                print(f"   üí° Action: Ne pas spam")
            
            print()
            
            # Sauvegarder dans Elasticsearch
            save_to_elasticsearch(event, prediction, probability)
            
            # Afficher un r√©sum√© tous les 20 √©v√©nements
            if total_processed % 20 == 0:
                conversion_rate = (predicted_purchases / total_processed) * 100
                high_prob_rate = (high_prob_purchases / total_processed) * 100
                
                print("=" * 60)
                print(f"üìä STATISTIQUES (apr√®s {total_processed} √©v√©nements)")
                print("=" * 60)
                print(f"   üõí Achats pr√©dits: {predicted_purchases} ({conversion_rate:.1f}%)")
                print(f"   ‚ùå Pas d'achat: {predicted_no_purchases}")
                print(f"   üî• Forte probabilit√© (>70%): {high_prob_purchases} ({high_prob_rate:.1f}%)")
                print("=" * 60 + "\n")
            
        except Exception as e:
            print(f"‚ùå Erreur de traitement : {e}\n")
            continue

except KeyboardInterrupt:
    print("\n" + "=" * 60)
    print("‚èπÔ∏è ARR√äT DU CONSUMER")
    print("=" * 60)
    
    if total_processed > 0:
        conversion_rate = (predicted_purchases / total_processed) * 100
        high_prob_rate = (high_prob_purchases / total_processed) * 100
        
        print(f"\nüìä R√âSUM√â FINAL")
        print(f"   Total √©v√©nements trait√©s: {total_processed}")
        print(f"   Achats pr√©dits: {predicted_purchases} ({conversion_rate:.1f}%)")
        print(f"   Pas d'achat: {predicted_no_purchases}")
        print(f"   Forte probabilit√© (>70%): {high_prob_purchases} ({high_prob_rate:.1f}%)")
    
    consumer.close()
    print("\n‚úÖ Consumer ferm√© proprement")

except Exception as e:
    print(f"\n‚ùå Erreur critique : {e}")
    consumer.close()